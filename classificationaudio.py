# -*- coding: utf-8 -*-
"""classificaationAudio.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W2jhtZn4FGsuOk6PqRlhhzjHW5YLiw7L
"""

pip install python_speech_features

import os
import tqdm as tq
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
from python_speech_features import mfcc,logfbank
import librosa

import pickle
from keras.callbacks import ModelCheckpoint
from cfg import Config

from keras.layers import Conv2D,MaxPool2D,Flatten,LSTM
from keras.layers import Dropout, Dense,TimeDistributed
from keras.models import Sequential
from keras.utils import to_categorical
from sklearn.utils.class_weight import compute_class_weight

from keras.models import load_model
from sklearn.metrics import accuracy_score

import zipfile

from google.colab import drive
drive.mount('/content/drive')

zip_ref = zipfile.ZipFile('../content/drive/My Drive/Audio-Classification-master.zip')
zip_ref.extractall()
zip_ref.close()

def plot_signals(signals):
    fig, axes = plt.subplots(nrows=2, ncols=5, sharex=False,
                             sharey=True, figsize=(20,5))
    fig.suptitle('Time Series', size=16)
    i = 0
    for x in range(2):
        for y in range(5):
            axes[x,y].set_title(list(signals.keys())[i])
            axes[x,y].plot(list(signals.values())[i])
            axes[x,y].get_xaxis().set_visible(False)
            axes[x,y].get_yaxis().set_visible(False)
            i += 1

def plot_fft(fft):
    fig, axes = plt.subplots(nrows=2, ncols=5, sharex=False,
                             sharey=True, figsize=(20,5))
    fig.suptitle('Fourier Transforms', size=16)
    i = 0
    for x in range(2):
        for y in range(5):
            data = list(fft.values())[i]
            Y, freq = data[0], data[1]
            axes[x,y].set_title(list(fft.keys())[i])
            axes[x,y].plot(freq, Y)
            axes[x,y].get_xaxis().set_visible(False)
            axes[x,y].get_yaxis().set_visible(False)
            i += 1

def plot_fbank(fbank):
    fig, axes = plt.subplots(nrows=2, ncols=5, sharex=False,
                             sharey=True, figsize=(20,5))
    fig.suptitle('Filter Bank Coefficients', size=16)
    i = 0
    for x in range(2):
        for y in range(5):
            axes[x,y].set_title(list(fbank.keys())[i])
            axes[x,y].imshow(list(fbank.values())[i],
                    cmap='hot', interpolation='nearest')
            axes[x,y].get_xaxis().set_visible(False)
            axes[x,y].get_yaxis().set_visible(False)
            i += 1

def plot_mfccs(mfccs):
    fig, axes = plt.subplots(nrows=2, ncols=5, sharex=False,
                             sharey=True, figsize=(20,5))
    fig.suptitle('Mel Frequency Cepstrum Coefficients', size=16)
    i = 0
    for x in range(2):
        for y in range(5):
            axes[x,y].set_title(list(mfccs.keys())[i])
            axes[x,y].imshow(list(mfccs.values())[i],
                    cmap='hot', interpolation='nearest')
            axes[x,y].get_xaxis().set_visible(False)
            axes[x,y].get_yaxis().set_visible(False)
            i += 1

def calc_fft(y,rate):
  n=len(y)
  freq=np.fft.rfftfreq(n,d=1/rate)
  Y=abs(np.fft.rfft(y)/n)
  return (Y,freq)

def envelope(y,rate,threshold):
  mask=[]
  y=pd.Series(y).apply(np.abs)
  y_mean=y.rolling(window=int(rate/10),min_periods=1,center=True).mean()
  for mean in y_mean:
    if mean>threshold:
      mask.append(True)
    else:
      mask.append(False)
  return mask

df=pd.read_csv('../content/audioj/instruments.csv')

df.set_index('fname',inplace=True)

for f in df.index:
  rate, signal=wavfile.read('../content/audioj/wavfiles/'+f)
  df.at[f, 'length']=signal.shape[0]/rate



classes=list(np.unique(df.label))

classes

class_dist=df.groupby(['label'])['length'].mean()

fig, ax=plt.subplots()
ax.set_title('Class Distribution',y=1.08)
ax.pie(class_dist,labels=class_dist.index,autopct='%1.1f%%',shadow=False,startangle=90)
ax.axis('equal')
plt.show()
df.reset_index(inplace=True)

for c in  classes:
  wav_file=df[df.label==c].iloc[0,0]
  signal,rate=librosa.load('../content/audioj/wavfiles/'+wav_file,sr=44100)
  mask=envelope(signal,rate,0.0005)
  signal=signal[mask]
  signals[c]=signal
  fft[c]=calc_fft(signal,rate)
  bank=logfbank(signal[:rate],rate,nfilt=26,nfft=1103).T
  fbank[c]=bank
  mel=mfcc(signal[:rate],rate,numcep=13,nfilt=26,nfft=1103).T
  mfccs[c]=mel

signals={}
fft={}
fbank={}
mfccs={}

plot_signals(signals)
plt.show()
plot_fft(fft)
plt.show()
plot_fbank(fbank)
plt.show()
plot_mfccs(mfccs)
plt.show()

if len(os.listdir('clean'))==0:
  for f in tq.tqdm(df.fname):
    signal, rate=librosa.load('../content/audio/wavfiles/'+f,sr=16000)
    mask=envelope(signal,rate,0.0005)
    wavfile.write(filename='../content/clean/'+f,rate=rate,data=signal[mask])

df=pd.read_csv('../content/audio/instruments.csv')
df.set_index('fname',inplace=True)

for f in df.index:
  rate, signal=wavfile.read('../content/clean/'+f)
  df.at[f, 'length']=signal.shape[0]/rate

df.head()

rate2, signal2=wavfile.read('../content/clean/0091fc7f.wav')
signal2.shape

classes=list(np.unique(df.label))
class_dist=df.groupby(['label'])['length'].mean()
fig, ax=plt.subplots()
ax.set_title('Class Distribution',y=1.08)
ax.pie(class_dist,labels=class_dist.index,autopct='%1.1f%%',shadow=False,startangle=90)
ax.axis('equal')
plt.show()
df.reset_index(inplace=True)

class_dist

df['length'].sum()

n_samples=2*int(df['length'].sum()/0.1)
prob_dist=class_dist/class_dist.sum()
choices=np.random.choice(class_dist.index,p=prob_dist)

choices

class Config:
  def __init__(self,mode='conv',nfilt=26,nfeat=13,nfft=512,rate=16000):
    self.mode=mode
    self.nfilt=nfilt
    self.nfeat=nfeat
    self.nfft=nfft
    self.rate=rate
    self.step=int(rate/10)
    self.model_path=os.path.join('../content/models',mode+'.model')
    self.p_path= os.path.join('pickles', mode+ '.p')

config=Config(mode='time')

df.set_index('fname',inplace=True)

df.head()

rand_class=np.random.choice(class_dist.index,p=prob_dist)
print(rand_class)
file =np.random.choice(df[df.label==rand_class].index)
print(file)

def check_data():
  if os.path.isfile(config.p_path):
    print('Loading data for {} model'.format(config.mode))
    with open(config.p_path,'rb') as handle:
      tmp=pickle.load(handle)
      return tmp
  else:
    return None

def build_rand_feat():
  tmp=check_data()
  if tmp:
    return tmp.data[0],tmp.data[1]
  X=[]
  y=[]
  _min, _max=float('inf'), -float('inf')
  for _ in tq.tqdm(range(n_samples)):
    rand_class=np.random.choice(class_dist.index,p=prob_dist)
    file =np.random.choice(df[df.label==rand_class].index)
    rate, wav=wavfile.read('../content/clean/'+file)
    label=df.at[file,'label']
    rand_index=np.random.randint(0,wav.shape[0]-config.step)
    sample=wav[rand_index:rand_index+config.step]
    X_sample=mfcc(sample,rate,numcep=config.nfeat,nfilt=config.nfilt,nfft=config.nfft)
    _min=min(np.amin(X_sample),_min)
    _max=max(np.amax(X_sample),_max)
    X.append(X_sample)
    y.append(classes.index(label))
  config.min=_min
  config.max=_max  
  X,y=np.array(X), np.array(y)
  X=(X-_min)/(_max-_min)
  if config.mode=='conv':
    X=X.reshape(X.shape[0],X.shape[1],X.shape[2],1)
  elif config.mode=='time':
    X=X.reshape(X.shape[0],X.shape[1],X.shape[2])
  y=to_categorical(y,num_classes=10)
  config.data=(X,y)

  with open(config.p_path,'wb') as handle:
    pickle.dump(config,handle,protocol=2)
  return X, y

def get_recurrent_model():
  model=Sequential()
  model.add(LSTM(128,return_sequences=True,input_shape=input_shape))
  model.add(LSTM(128,return_sequences=True))
  model.add(Dropout(0.5))
  model.add(TimeDistributed(Dense(64,activation='relu')))
  model.add(TimeDistributed(Dense(32,activation='relu')))
  model.add(TimeDistributed(Dense(16,activation='relu')))
  model.add(TimeDistributed(Dense(8,activation='relu')))
  model.add(Flatten())
  model.add(Dense(10,activation='softmax'))
  model.summary()
  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])
  return model

def get_conv_model():
  model=Sequential()
  model.add(Conv2D(16,(3,3),activation='relu',strides=(1,1),padding='same',input_shape=input_shape))
  model.add(Conv2D(32,(3,3),activation='relu',strides=(1,1),padding='same'))
  model.add(Conv2D(64,(3,3),activation='relu',strides=(1,1),padding='same'))
  model.add(Conv2D(128,(3,3),activation='relu',strides=(1,1),padding='same'))
  model.add(MaxPool2D(2,2))
  model.add(Dropout(0.5))
  model.add(Flatten())
  model.add(Dense(128,activation='relu'))
  model.add(Dense(64,activation='relu'))
  model.add(Dense(10,activation='softmax'))
  model.summary()
  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])
  return model

if config.mode=='conv':
  X,y=build_rand_feat()
  y_flat=np.argmax(y,axis=1)
  input_shape=(X.shape[1],X.shape[2],1)
  model=get_conv_model()
elif config.mode=='time':
  X,y=build_rand_feat() 
  y_flat=np.argmax(y,axis=1)
  input_shape=(X.shape[1],X.shape[2])
  model=get_recurrent_model()

class_weight=compute_class_weight('balanced',np.unique(y_flat),y_flat)

checkpoint= ModelCheckpoint(config.model_path,monitor='val_acc',verbose=1,mode='max',save_best_only=True,save_weights_only=False,period=1)

model.fit(X,y,epochs=10,batch_size=32,shuffle=True,validation_split=0.1,callbacks=[checkpoint])

model.save(config.model_path)

def build_predictions(audio_dir):
  y_true=[]
  y_pred=[]
  fn_prob={}
  print('extracting features for audio')
  for fn in tq.tqdm(os.listdir(audio_dir)):
    rate,wav=wavfile.read(os.path.join(audio_dir,fn))
    label=fn2class[fn]
    c=classes.index(label)
    y_prob=[] 
    for i in range(0,wav.shape[0]-config.step,config.step):
      sample=wav[i:i+config.step]
      x=mfcc(sample,rate,numcep=config.nfeat,nfilt=config.nfilt,nfft=config.nfft)
      x=(x-config.min)/(config.max-config.min)
      if config.mode=='conv':
        x=x.reshape(1,x.shape[0],x.shape[1],1)
      elif config.mode=='time':
        x=x.reshape(1,x.shape[0],x.shape[1])
      y_hat=model.predict(x)
      y_prob.append(y_hat)
      y_pred.append(np.argmax(y_hat))
      y_true.append(c)
    fn_prob[fn]=np.mean(y_prob,axis=0).flatten()
  return y_true,y_pred,fn_prob

df=pd.read_csv('../content/audio/instruments.csv')
classes=list(np.unique(df.label))
fn2class=dict(zip(df.fname,df.label))
p_path=os.path.join('pickles','conv.p')
with open(p_path,'rb') as handle:
  config=pickle.load(handle)
model=load_model(config.model_path)
y_true,y_pred,fn_prob=build_predictions('../content/clean/')
acc_score=accuracy_score(y_true=y_true,y_pred=y_pred)
y_probs=[]
for i,row in df.iterrows():
  y_prob=fn_prob[row.fname]
  y_pro bs.append(y_prob)
  for c,p in zip(classes, y_prob):
    df.at[i,c]=p
y_pred=[classes[np.argmax(y)] for y in y_probs]
df['y_pred']=y_pred
df.to_csv('predictions.csv',index=False)